{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Scientific Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "  - [Scientific Libraries](#Scientific-Libraries)  \n",
    "  - [The Need for Speed](#The-Need-for-Speed)  \n",
    "  - [Vectorization](#Vectorization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific Libraries\n",
    "\n",
    "One obvious reason we use scientif libraries is because they implement routines we want to use.\n",
    "\n",
    "But another (more important) reason is that pure Python, while flexible and elegant, is not fast. So we need libraries that are designed to accelerate execution of Python code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python's Scientific Ecosystem\n",
    "\n",
    "In terms of popularity, the big four in the world of scientific Python libraries are:\n",
    "- NumPy: provides a basic array data type and functions for acting on these arrays.\n",
    "- SciPy: builds on NumPy by adding the kinds of numerical methods that are routinely used in science.\n",
    "- Matplotlib: generates figures, with a focus on plotting data stored in NumPy arrays.\n",
    "- Pandas: provides types and functions for empirical work (e.g., manipulating data).\n",
    "\n",
    "We will also cover Numba, which accelerates execution via JIT compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Need for Speed\n",
    "\n",
    "Higher level languages like Python are optimized for humans. This means that the programmer can leave many details to the runtime environment, such as\n",
    "\n",
    "- specifying variable types  \n",
    "- memory allocation/deallocation, etc.  \n",
    "\n",
    "The upside is that, compared to low-level languages, Python is typically faster to write, less error prone and  easier to debug.\n",
    "\n",
    "The downside is that Python is harder to optimize — that is, turn into fast machine code — than languages like C or Fortran.\n",
    "Indeed, the standard implementation of Python (called CPython) cannot match the speed of compiled languages such as C or Fortran. \n",
    "\n",
    "Does that mean that we should just switch to C or Fortran for everything?\n",
    "The answer is no, this is because\n",
    "\n",
    "1. Of any given program, relatively few lines are ever going to be time-critical.\n",
    "1. For those lines of code that *are* time-critical, we can achieve C-like speed using Python's scientific libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are the Bottlenecks?\n",
    "\n",
    "Let’s start by trying to understand why high level languages like Python are slower than compiled code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Typing vs Static Types\n",
    "\n",
    "Consider this Python operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a, b = 10, 10\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for this simple operation, the Python interpreter has a fair bit of work to do.\n",
    "For example, in the statement `a + b`, the interpreter has to know which\n",
    "operation to invoke: If `a` and `b` are strings, then `a + b` requires string concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a, b = 'foo', 'bar'\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `a` and `b` are lists, then `a + b` requires list concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a, b = ['foo'], ['bar']\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the operator + is overloaded — its action depends on the type of the objects on which it acts. \n",
    "As a result, Python must check the type of the objects and then call the correct operation. \n",
    "This involves substantial overheads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiled languages avoid these overheads with explicit, static types. \n",
    "For example, consider the following C code, which sums the integers from 1 to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "```c\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(void) {\n",
    "    int i;\n",
    "    int sum = 0;\n",
    "    for (i = 1; i <= 10; i++) {\n",
    "        sum = sum + i;\n",
    "    }\n",
    "    printf(\"sum = %d\\n\", sum);\n",
    "    return 0;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables `i` and `sum` are explicitly declared to be integers. Hence, the meaning of addition here is completely unambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Access\n",
    "\n",
    "Another drag on speed for high level languages is data access. \n",
    "To illustrate, let’s consider the problem of summing some data — say, a collection of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summing with Compiled Code\n",
    "In C or Fortran, these integers would typically be stored in an array, which\n",
    "is a simple data structure for storing homogeneous data. \n",
    "Such an array is stored in a single contiguous block of memory:\n",
    "\n",
    "- In modern computers, memory addresses are allocated to each byte (one byte = 8 bits)  \n",
    "- For example, a 64 bit integer is stored in 8 bytes of memory  \n",
    "- An array of $ n $ such integers occupies $ 8n $ **consecutive** memory slots  \n",
    "\n",
    "Moreover, the compiler is made aware of the data type by the programmer, in this case 64 bit integers.  \n",
    "Hence, each successive data point can be accessed by shifting forward in memory\n",
    "space by a known and fixed amount, in this case 8 bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summing in Pure Python\n",
    "Python tries to replicate these ideas to some degree. \n",
    "For example, in the standard Python implementation (CPython), list elements are placed in memory locations that are in a sense contiguous. \n",
    "\n",
    "However, these list elements are more like pointers to data rather than actual data. \n",
    "Hence, there is still overhead involved in accessing the data values themselves. \n",
    "This is a considerable drag on speed.\n",
    "In fact, it’s generally true that memory traffic is a major culprit when it comes to slow execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "There is a clever method called **vectorization** that can be used to speed up high level languages in numerical applications.\n",
    "\n",
    "The key idea is to send array processing operations in batch to pre-compiled and efficient native machine code. The machine code itself is typically compiled from carefully optimized C or Fortran.\n",
    "\n",
    "This clever idea dates back to MATLAB, which uses vectorization extensively.\n",
    "This can greatly accelerate many (but not all) numerical computations.\n",
    "\n",
    "Let's see how vectorization works in Python, using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Arrays\n",
    "\n",
    "First let’s run some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s try this non-vectorized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "start = time.time() # record start time\n",
    "\n",
    "n = 100000\n",
    "sum = 0\n",
    "for i in range(n):\n",
    "    x = random.uniform(0, 1)\n",
    "    sum += x**2\n",
    "    \n",
    "end = time.time() # record end time\n",
    "\n",
    "elapsed_time = end - start # test timing\n",
    "print(elapsed_time)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followng vectorized code achieves the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "start = time.time() # record start time\n",
    "\n",
    "n = 100000\n",
    "x = np.random.uniform(0, 1, n)\n",
    "np.sum(x**2)\n",
    "\n",
    "end = time.time() # record end time\n",
    "\n",
    "elapsed_time = end - start # test timing\n",
    "print(elapsed_time)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second code block runs much faster. \n",
    "The reason is that in the second implementation we have broken the loop down into three basic operations:\n",
    "\n",
    "1. draw `n` uniforms  \n",
    "1. square them  \n",
    "1. sum them  \n",
    "\n",
    "These are sent as batch operators to optimized machine code.\n",
    "Apart from minor overheads associated with sending data back and forth, the result is C or Fortran-like speed. \n",
    "\n",
    "When we run batch operations on arrays like this, we say that the code is *vectorized*. Vectorized code is typically fast and efficient. It is also surprisingly flexible, in the sense that many operations can be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Functions\n",
    "\n",
    "Many functions provided by NumPy are so-called *universal functions* — also called [ufuncs](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\n",
    "\n",
    "This means that they\n",
    "\n",
    "- map scalars into scalars, as expected  \n",
    "- map arrays into arrays, acting element-wise  \n",
    "\n",
    "For example, `np.cos` is a ufunc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.cos(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.cos(np.linspace(0, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By exploiting ufuncs, many operations can be vectorized.\n",
    "\n",
    "For example, consider the problem of maximizing a function $ f $ of two\n",
    "variables $ (x,y) $ over the square $ [-a, a] \\times [-a, a] $.\n",
    "For $ f $ and $ a $ let’s choose:\n",
    "\n",
    "$$\n",
    "f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n",
    "\\quad \\text{and} \\quad\n",
    "a = 3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maximize $f$, we’re going to use a naive grid search:\n",
    "\n",
    "1. Evaluate $ f $ for all $ (x,y) $ in a grid on the square  \n",
    "1. Return the maximum of observed values  \n",
    "\n",
    "Here’s a non-vectorized version that uses Python loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3, 3, 1000)\n",
    "m = -np.inf\n",
    "\n",
    "start = time.time() # record start time\n",
    "\n",
    "### non-vectorized version\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        z = f(x, y)\n",
    "        if z > m:\n",
    "            m = z\n",
    "            \n",
    "end = time.time() # record end time\n",
    "\n",
    "elapsed_time = end - start # test timing\n",
    "print(elapsed_time)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s a vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3, 3, 1000)\n",
    "x, y = np.meshgrid(grid, grid)\n",
    "\n",
    "start = time.time() # record start time\n",
    "\n",
    "### vectorized version\n",
    "np.max(f(x, y))\n",
    "\n",
    "end = time.time() # record end time\n",
    "\n",
    "elapsed_time = end - start # test timing\n",
    "print(elapsed_time)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the vectorized version, all the looping takes place in compiled code, which makes it much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Vectorization\n",
    "\n",
    "At its best, vectorization yields fast, simple code. \n",
    "However, it’s not without disadvantages.\n",
    "\n",
    "- One issue is that it can be highly memory intensive. \n",
    "\n",
    "For example, the vectorized maximization routine above is far more memory intensive than the non-vectorized version that preceded it. \n",
    "This is because vectorization tends to create many intermediate arrays before producing the final calculation.\n",
    "\n",
    "- Another issue is that not all algorithms can be vectorized. \n",
    "\n",
    "In these kinds of settings, we need to go back to loops. \n",
    "Fortunately, there are alternative ways to speed up Python loops that work in almost any setting. \n",
    "One example is through Numba that can generate extremely fast and efficient code through **just in time (JIT) compilation**. "
   ]
  }
 ],
 "metadata": {
  "filename": "numba.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "title": "Numba"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
